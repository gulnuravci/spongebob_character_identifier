{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPMCc/VUCvar7l9UdBhPksW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "94b26ed853c04ff7832bfad3f662212b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6adc63fcce3440e18820d001d0930014",
              "IPY_MODEL_6ca591479f5342a4955c3831324b26d5",
              "IPY_MODEL_48817636a183440586a28c407758889e"
            ],
            "layout": "IPY_MODEL_0b2f49ff4f704c9b9d8c5bab9d889d41"
          }
        },
        "6adc63fcce3440e18820d001d0930014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_835411953d544295bc6d6273aa3c8e5b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5ca9da9d482148fa8f8b8a9afb4b4998",
            "value": "100%"
          }
        },
        "6ca591479f5342a4955c3831324b26d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ab20a5680e74b0384ee1fa8fff7f6e1",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8b19ca2ad664b96a7fec8f78c8693b0",
            "value": 10
          }
        },
        "48817636a183440586a28c407758889e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b5ffa03e570420380747c5f7c505d3b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0f0f675d73c948a69b74b7a4dd0d50be",
            "value": " 10/10 [05:45&lt;00:00, 33.86s/it]"
          }
        },
        "0b2f49ff4f704c9b9d8c5bab9d889d41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "835411953d544295bc6d6273aa3c8e5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ca9da9d482148fa8f8b8a9afb4b4998": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ab20a5680e74b0384ee1fa8fff7f6e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8b19ca2ad664b96a7fec8f78c8693b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b5ffa03e570420380747c5f7c505d3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f0f675d73c948a69b74b7a4dd0d50be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gulnuravci/spongebob_character_identifier/blob/main/spongebob_character_identifier_deployment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# imports"
      ],
      "metadata": {
        "id": "ebTTu214Viv-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8JuXINZVXCc",
        "outputId": "50f351af-993c-46cd-ee74-99ecc234ea2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m302.7/302.7 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m311.1/311.1 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m407.5/407.5 kB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mGradio version: 4.3.0\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  import gradio as gr\n",
        "except:\n",
        "  !pip -q install gradio\n",
        "  import gradio as gr\n",
        "\n",
        "print(f\"Gradio version: {gr.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import random\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "from pathlib import Path\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "from timeit import default_timer as timer\n",
        "from PIL import Image\n",
        "from timeit import default_timer as timer\n",
        "from tqdm.auto import tqdm\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    !pip install -q torchinfo\n",
        "    from torchinfo import summary\n",
        "\n",
        "try:\n",
        "  import torchmetrics\n",
        "except:\n",
        "  !pip install -q torchmetrics\n",
        "  import torchmetrics"
      ],
      "metadata": {
        "id": "3C7Nm3nwWnSY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e57d72ca-bb0b-4ecf-fe45-6bf8479bc2c0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/805.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.7/805.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m358.4/805.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[32m655.4/805.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary spongebob_character_identifier files from github\n",
        "try:\n",
        "  import data_setup, engine, model_builder, transfer_learning_model_builder, utils\n",
        "except:\n",
        "  !git clone https://github.com/gulnuravci/spongebob_character_identifier\n",
        "  !cp spongebob_character_identifier/spongebob_character_identifier/data_setup.py .\n",
        "  !cp spongebob_character_identifier/spongebob_character_identifier/engine.py .\n",
        "  !cp spongebob_character_identifier/spongebob_character_identifier/model_builder.py .\n",
        "  !cp spongebob_character_identifier/spongebob_character_identifier/transfer_learning_model_builder.py .\n",
        "  !cp spongebob_character_identifier/spongebob_character_identifier/utils.py .\n",
        "  !rm -rf spongebob_character_identifier\n",
        "  import data_setup, engine, model_builder, transfer_learning_model_builder, utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5RWpxvlWZZS",
        "outputId": "1bc4c8b4-6e41-4728-f041-6e416d517f71"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'spongebob_character_identifier'...\n",
            "remote: Enumerating objects: 1820, done.\u001b[K\n",
            "remote: Counting objects: 100% (380/380), done.\u001b[K\n",
            "remote: Compressing objects: 100% (348/348), done.\u001b[K\n",
            "remote: Total 1820 (delta 33), reused 354 (delta 22), pack-reused 1440\u001b[K\n",
            "Receiving objects: 100% (1820/1820), 220.51 MiB | 21.26 MiB/s, done.\n",
            "Resolving deltas: 100% (118/118), done.\n",
            "Updating files: 100% (1492/1492), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# set up device"
      ],
      "metadata": {
        "id": "zMiN0RJaWSeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = utils.setup_target_device(device=\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvUpL4YOWTsN",
        "outputId": "d4ee4526-0966-4d50-d582-b49f7cc6e1cb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current device: cuda\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# get data and set up directories"
      ],
      "metadata": {
        "id": "l0qij849W-p6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import data\n",
        "DATA_NAME = \"character_images\"\n",
        "GITHUB_URL = \"https://github.com/gulnuravci/spongebob_character_identifier/raw/main/character_images.zip\"\n",
        "data_setup.import_data_from_github(data_name=DATA_NAME, github_raw_url=GITHUB_URL)\n",
        "\n",
        "# Setup directories\n",
        "data_dir = Path(\"data\") / DATA_NAME\n",
        "train_dir = data_dir / \"train\"\n",
        "test_dir = data_dir / \"test\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICpv2kwAW-_X",
        "outputId": "68ed2c6b-76c4-448e-8c71-cece093bb891"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/character_images directory does not exist, importing...\n",
            "Import complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the directory path\n",
        "directory_path = \"/content/models\"\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not os.path.exists(directory_path):\n",
        "    os.makedirs(directory_path)\n",
        "\n",
        "# Check if the directory has been created\n",
        "if os.path.exists(directory_path):\n",
        "    print(f\"Directory '{directory_path}' has been created.\")\n",
        "else:\n",
        "    print(f\"Failed to create directory '{directory_path}'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYLsTQ50XBZM",
        "outputId": "019cd3c5-e3fc-4955-a80e-16215c156ce4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory '/content/models' has been created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# efficientnet_b2"
      ],
      "metadata": {
        "id": "IoEDf-kWXDP8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## create model and get transform\n"
      ],
      "metadata": {
        "id": "Gm1iOVNrXLCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import efficientnet_b2, EfficientNet_B2_Weights\n",
        "\n",
        "# Set the name of the model to save\n",
        "MODEL_NAME = \"model_efficientnet_b2\"\n",
        "NOTES = \"Using transfer learning with PyTorch pre-trained model 'efficientnet_b2'\"\n",
        "\n",
        "# Setup hyperparameters\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.001\n",
        "OUT_FEATURES = 10\n",
        "\n",
        "# Create model\n",
        "effnetb2 = transfer_learning_model_builder.create_effnetb2(out_features=OUT_FEATURES,\n",
        "                                                           device=device)\n",
        "\n",
        "# Get transform\n",
        "weights = EfficientNet_B2_Weights.DEFAULT\n",
        "auto_transforms = weights.transforms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6xN5Y8BXJQy",
        "outputId": "d0d545f1-5b6a-4e7d-fe3f-c89992f7bd4f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b2_rwightman-bcdf34b7.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b2_rwightman-bcdf34b7.pth\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35.2M/35.2M [00:00<00:00, 59.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Created new effnetb2 model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## create dataloaders, loss, and optimizer"
      ],
      "metadata": {
        "id": "80PZGDijXRh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and testing DataLoaders as well as get a list of class names\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
        "                                                                               test_dir=test_dir,\n",
        "                                                                               train_transform=auto_transforms,\n",
        "                                                                               test_transform=auto_transforms,\n",
        "                                                                               batch_size=BATCH_SIZE,\n",
        "                                                                               device=device)"
      ],
      "metadata": {
        "id": "9KzgTA89XR36"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(effnetb2.parameters(),\n",
        "                             lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "_NocVu3jXUb9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train"
      ],
      "metadata": {
        "id": "aI5OrXrAXWx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start the timer\n",
        "start_time = timer()\n",
        "\n",
        "# Setup training and save the results\n",
        "effnetb2_results = engine.train(model=effnetb2,\n",
        "                             train_dataloader=train_dataloader,\n",
        "                             test_dataloader=test_dataloader,\n",
        "                             optimizer=optimizer,\n",
        "                             loss_fn=loss_fn,\n",
        "                             epochs=NUM_EPOCHS,\n",
        "                             device=device,\n",
        "                             writer=utils.create_writer(experiment_name=\"original\",\n",
        "                                                 model_name=MODEL_NAME,\n",
        "                                                 extra=f\"{NUM_EPOCHS}_epochs\"))\n",
        "\n",
        "# End the timer and print out how long it took\n",
        "end_time = timer()\n",
        "effnetb2_total_time = end_time-start_time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251,
          "referenced_widgets": [
            "94b26ed853c04ff7832bfad3f662212b",
            "6adc63fcce3440e18820d001d0930014",
            "6ca591479f5342a4955c3831324b26d5",
            "48817636a183440586a28c407758889e",
            "0b2f49ff4f704c9b9d8c5bab9d889d41",
            "835411953d544295bc6d6273aa3c8e5b",
            "5ca9da9d482148fa8f8b8a9afb4b4998",
            "8ab20a5680e74b0384ee1fa8fff7f6e1",
            "f8b19ca2ad664b96a7fec8f78c8693b0",
            "2b5ffa03e570420380747c5f7c505d3b",
            "0f0f675d73c948a69b74b7a4dd0d50be"
          ]
        },
        "id": "zAUiXrLQXXke",
        "outputId": "5cdedd66-264d-4fe1-c4a8-fac33a6640f4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Created SummaryWriter, saving to: runs/2023-11-14/original/model_efficientnet_b2/10_epochs...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94b26ed853c04ff7832bfad3f662212b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 1.8288 | train_acc: 0.5760 | test_loss: 1.2592 | test_acc: 0.9258\n",
            "Epoch: 2 | train_loss: 1.0018 | train_acc: 0.9437 | test_loss: 0.7517 | test_acc: 0.9648\n",
            "Epoch: 3 | train_loss: 0.6447 | train_acc: 0.9719 | test_loss: 0.5141 | test_acc: 0.9648\n",
            "Epoch: 4 | train_loss: 0.4629 | train_acc: 0.9646 | test_loss: 0.3970 | test_acc: 0.9570\n",
            "Epoch: 5 | train_loss: 0.3655 | train_acc: 0.9750 | test_loss: 0.3269 | test_acc: 0.9648\n",
            "Epoch: 6 | train_loss: 0.2934 | train_acc: 0.9781 | test_loss: 0.2777 | test_acc: 0.9688\n",
            "Epoch: 7 | train_loss: 0.2422 | train_acc: 0.9833 | test_loss: 0.2446 | test_acc: 0.9766\n",
            "Epoch: 8 | train_loss: 0.2130 | train_acc: 0.9906 | test_loss: 0.2260 | test_acc: 0.9727\n",
            "Epoch: 9 | train_loss: 0.1930 | train_acc: 0.9865 | test_loss: 0.2029 | test_acc: 0.9688\n",
            "Epoch: 10 | train_loss: 0.1757 | train_acc: 0.9875 | test_loss: 0.1911 | test_acc: 0.9727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## save model"
      ],
      "metadata": {
        "id": "-6xDyZ4gjRDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "utils.save_model_with_hyperparameters(model=effnetb2,\n",
        "                                      model_results=effnetb2_results,\n",
        "                                      target_dir=\"models\",\n",
        "                                      model_name=MODEL_NAME,\n",
        "                                      num_epochs=NUM_EPOCHS,\n",
        "                                      batch_size=BATCH_SIZE,\n",
        "                                      hidden_units=\"N/A\",\n",
        "                                      learning_rate=LEARNING_RATE,\n",
        "                                      image_size=\"224x224\",\n",
        "                                      train_dataloader_length=len(train_dataloader),\n",
        "                                      test_dataloader_length=len(test_dataloader),\n",
        "                                      notes=NOTES)"
      ],
      "metadata": {
        "id": "Wp5YxEI5jSUG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# deployment"
      ],
      "metadata": {
        "id": "PBWZMTfxYKeh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## to gradio (temporary)"
      ],
      "metadata": {
        "id": "CF6CKuFYfv4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Put EffNetB2 on CPU\n",
        "effnetb2.to(\"cpu\")\n",
        "\n",
        "# Check the device\n",
        "next(iter(effnetb2.parameters())).device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NP6dNx62YLPv",
        "outputId": "dbfcfa2f-63e3-4cb2-f2f9-3bda20518b24"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(img) -> Tuple[Dict, float]:\n",
        "  \"\"\"Transforms and performs a prediction on img and returns prediction and time taken.\n",
        "  \"\"\"\n",
        "  # Start the timer\n",
        "  start_time = timer()\n",
        "\n",
        "  # Transform the target image and add a batch dimension\n",
        "  img = auto_transforms(img).unsqueeze(dim=0)\n",
        "\n",
        "  # Put model into evaluation mode and turn on inference mode\n",
        "  effnetb2.eval()\n",
        "  with torch.inference_mode():\n",
        "    # Pass the transformed image through the model and turn the prediction logits into prediction probabilities\n",
        "    pred_probs = torch.softmax(effnetb2(img), dim=1)\n",
        "\n",
        "  # Create a prediction label and prediction probability dictionary for each prediction class (required format for Gradio's output parameter)\n",
        "  pred_labels_and_probs = {class_names[i]:float(pred_probs[0][i]) for i in range(len(class_names))}\n",
        "\n",
        "  # Calculate the prediction time\n",
        "  pred_time = round(timer() - start_time)\n",
        "\n",
        "  # Return the prediction dictionary and prediction time\n",
        "  return pred_labels_and_probs, pred_time"
      ],
      "metadata": {
        "id": "8iRJJDweYU21"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of all test image filepaths\n",
        "test_data_paths = list(Path(test_dir).glob(\"*/*.jpg\"))\n",
        "\n",
        "# Randomly select a test image path\n",
        "random_image_path = random.sample(test_data_paths, k=1)[0]\n",
        "\n",
        "# Open the target image\n",
        "image = Image.open(random_image_path)\n",
        "print(f\"[INFO] Predicting on image at path: {random_image_path}\\n\")\n",
        "\n",
        "# Predict on the target image and print out the outputs\n",
        "pred_dict, pred_time = predict(img=image)\n",
        "print(f'Prediction label and probability dictionary: \\n{pred_dict}')\n",
        "print(f\"Prediction time: {pred_time} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESPS7LTDZvGG",
        "outputId": "23f1e12e-864c-4a99-dc50-776654edbfe2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Predicting on image at path: data/character_images/test/patrick_star/patrick_star_86.jpg\n",
            "\n",
            "Prediction label and probability dictionary: \n",
            "{'eugene_h_krabs': 0.015761101618409157, 'gary_the_snail': 0.004570010583847761, 'karen_plankton': 0.0426739901304245, 'mrs_puff': 0.014805634506046772, 'patrick_star': 0.8181440234184265, 'pearl_krabs': 0.016805436462163925, 'sandy_cheeks': 0.030565641820430756, 'sheldon_j_plankton': 0.006081614177674055, 'spongebob_squarepants': 0.03927656635642052, 'squidward_tentacles': 0.011315987445414066}\n",
            "Prediction time: 0 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of example inputs to our Gradio demo\n",
        "example_list = [[str(filepath)] for filepath in random.sample(test_data_paths, k=3)]\n",
        "example_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqB3Q6YGbLgZ",
        "outputId": "148366ac-7841-4a6a-b76d-9d4a53550ada"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['data/character_images/test/karen_plankton/karen_plankton_20.jpg'],\n",
              " ['data/character_images/test/sandy_cheeks/sandy_cheeks_12.jpg'],\n",
              " ['data/character_images/test/pearl_krabs/pearl_krabs_8.jpg']]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "title = \"Spongebob Chracter Identifier ğŸ§½ğŸ‘–ğŸ™ğŸ¦€ğŸ¿ï¸ğŸğŸ”ğŸ³ğŸ–¥ï¸\"\n",
        "description = \"An EfficientNetB2 feature extractor computer vision model to classify between 10 character from Spongebob Squarepants: Spongebob, Patrick, Squidward, Gary, Mr. Krabs, Mrs.Puff, Sandy, Plankton, Karen, and Pearl\"\n",
        "article = \"Read more at: [Spongebob Character Identifier](https://gulnuravci.github.io/scripts/project_pages/spongebob_identifier.html)\"\n",
        "demo = gr.Interface(fn=predict, # mapping function from input to output\n",
        "                    inputs=gr.Image(type=\"pil\"), # what are the inputs?\n",
        "                    outputs=[gr.Label(num_top_classes=10, label=\"Predictions\"), # what are the outputs?\n",
        "                             gr.Number(label=\"Prediction time (s)\")], # our fn has two outputs, therefore we have two outputs\n",
        "                    examples=example_list,\n",
        "                    title=title,\n",
        "                    description=description,\n",
        "                    article=article)\n",
        "\n",
        "demo.launch(debug=False, # print errors locally?\n",
        "            share=True) # generate a publically shareable URL?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "9YdZ0z5Ecihp",
        "outputId": "99fb89f6-093d-4b7b-d0aa-e90e077cb9e9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://4b05c141b12739cedb.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://4b05c141b12739cedb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## to hugging face spaces (permanent)"
      ],
      "metadata": {
        "id": "ExzIJXaxf0FS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create demo path\n",
        "spongebob_character_identifier_path = Path(\"demos/spongebob_character_identifier/\")\n",
        "\n",
        "# Remove files that might already exist and create new directory\n",
        "if spongebob_character_identifier_path.exists():\n",
        "  shutil.rmtree(spongebob_character_identifier_path)\n",
        "  spongebob_character_identifier_path.mkdir(parents=True, # make the parent folders?\n",
        "                                            exist_ok=True) # create it even if it already exists?\n",
        "else:\n",
        "  # If the file doesn't exist, create it anyway\n",
        "  spongebob_character_identifier_path.mkdir(parents=True, # make the parent folders?\n",
        "                                            exist_ok=True) # create it even if it already exists?\n",
        "\n",
        "# Check what's in the folder\n",
        "!ls demos/spongebob_character_identifier/"
      ],
      "metadata": {
        "id": "B_5sbbHFf3kv"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an examples directory\n",
        "spongebob_character_identifier_examples_path = spongebob_character_identifier_path / \"examples\"\n",
        "spongebob_character_identifier_examples_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Collect three random test dataset image paths\n",
        "spongebob_character_identifier_examples = [Path('data/character_images/test/gary_the_snail/gary_the_snail_54.jpg'),\n",
        "                                           Path('data/character_images/test/squidward_tentacles/squidward_tentacles_101.jpg'),\n",
        "                                           Path('data/character_images/test/pearl_krabs/pearl_krabs_45.jpg')]\n",
        "\n",
        "# Copy the three random images to the examples directory\n",
        "for example in spongebob_character_identifier_examples:\n",
        "  destination = spongebob_character_identifier_examples_path / example.name\n",
        "  print(f\"[INFO] Copying {example} to {destination}\")\n",
        "  shutil.copy2(src=example, dst=destination)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WttAJadtg21H",
        "outputId": "730f53c4-4648-40d0-82e0-7dbc853e6364"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Copying data/character_images/test/gary_the_snail/gary_the_snail_54.jpg to demos/spongebob_character_identifier/examples/gary_the_snail_54.jpg\n",
            "[INFO] Copying data/character_images/test/squidward_tentacles/squidward_tentacles_101.jpg to demos/spongebob_character_identifier/examples/squidward_tentacles_101.jpg\n",
            "[INFO] Copying data/character_images/test/pearl_krabs/pearl_krabs_45.jpg to demos/spongebob_character_identifier/examples/pearl_krabs_45.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get example filepaths in a list of lists\n",
        "example_list = [[\"examples/\" + example] for example in os.listdir(spongebob_character_identifier_examples_path)]\n",
        "example_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99DhIKaLipOr",
        "outputId": "340eca49-c834-462e-a9f4-4511fda721d1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['examples/gary_the_snail_54.jpg'],\n",
              " ['examples/pearl_krabs_45.jpg'],\n",
              " ['examples/squidward_tentacles_101.jpg']]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a source path for our target model\n",
        "effnetb2_spongebob_character_identifier_model_path = \"models/model_efficientnet_b2.pth\"\n",
        "\n",
        "# Create a destination path for our target model\n",
        "effnetb2_spongebob_character_identifier_model_destination = spongebob_character_identifier_path / effnetb2_spongebob_character_identifier_model_path.split(\"/\")[1]\n",
        "\n",
        "# Try to move the file\n",
        "try:\n",
        "  print(f\"[INFO] Attempting to move {effnetb2_spongebob_character_identifier_model_path} to {effnetb2_spongebob_character_identifier_model_destination}\")\n",
        "\n",
        "  # Move the model\n",
        "  shutil.move(src=effnetb2_spongebob_character_identifier_model_path,\n",
        "              dst=effnetb2_spongebob_character_identifier_model_destination)\n",
        "\n",
        "  print(f\"[INFO] Model move complete.\")\n",
        "\n",
        "# If the model has already been moved, check if it exists\n",
        "except:\n",
        "  print(f\"[INFO] No model found at {effnetb2_spongebob_character_identifier_model_path}, perhaps its already been move?\")\n",
        "  print(f\"[INFO] Model exists at {effnetb2_spongebob_character_identifier_model_destination} : {effnetb2_spongebob_character_identifier_model_destination.exists()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2SxrjwOi7IQ",
        "outputId": "060146a9-e081-4a6f-9e21-2cdba3d51f75"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Attempting to move models/model_efficientnet_b2.pth to demos/spongebob_character_identifier/model_efficientnet_b2.pth\n",
            "[INFO] Model move complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile demos/spongebob_character_identifier/model.py\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch import nn\n",
        "from torchvision.models import efficientnet_b2, EfficientNet_B2_Weights\n",
        "from torchvision.models._api import WeightsEnum\n",
        "from torch.hub import load_state_dict_from_url\n",
        "\n",
        "def create_effnetb2_model(num_classes:int=10,\n",
        "                          seed:int=42):\n",
        "  \"\"\"Creates an EficientNetB2 feature extractor model and transforms.\n",
        "\n",
        "  Args:\n",
        "    num_classes (int, optional): number of classes in the classifier head. Defaults to 10.\n",
        "    seed (int, optional): random seed value. Defaults to 42.\n",
        "\n",
        "  Returns:\n",
        "    model (torch.nn.Module): EffNetB2 feature extractor model.\n",
        "    transforms (torchvision.transforms): EfnetB2 image transforms.\n",
        "  \"\"\"\n",
        "  # Fix for wrong hash error from: https://github.com/pytorch/vision/issues/7744\n",
        "  def get_state_dict(self, *args, **kwargs):\n",
        "      kwargs.pop(\"check_hash\")\n",
        "      return load_state_dict_from_url(self.url, *args, **kwargs)\n",
        "  WeightsEnum.get_state_dict = get_state_dict\n",
        "\n",
        "  # Create EffNetB2 pretrained weights, transforms and model\n",
        "  weights = EfficientNet_B2_Weights.DEFAULT\n",
        "  transforms = weights.transforms()\n",
        "  model = efficientnet_b2(weights=weights)\n",
        "\n",
        "  # Freeze all layers in base model\n",
        "  for param in model.features.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "  # Change the classifier head with random seed for reproducibility\n",
        "  torch.manual_seed(seed)\n",
        "  model.classifier = nn.Sequential(\n",
        "      nn.Dropout(p=0.3),\n",
        "      nn.Linear(in_features=1408, out_features=num_classes)\n",
        "  )\n",
        "\n",
        "  return model, transforms\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95b0OP7WkdQZ",
        "outputId": "f16c0e6d-6fc4-4aee-e510-b9d074a2cd7c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing demos/spongebob_character_identifier/model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile demos/spongebob_character_identifier/app.py\n",
        "\n",
        "### Imports and class names setup ###\n",
        "import gradio as gr\n",
        "import os\n",
        "import torch\n",
        "\n",
        "from model import create_effnetb2_model\n",
        "from timeit import default_timer as timer\n",
        "from typing import Tuple, Dict\n",
        "\n",
        "# Setup class names\n",
        "class_names = [\"eugene_h_krabs\", \"gary_the_snail\", \"karen_plankton\", \"mrs_puff\", \"patrick_star\", \"pearl_krabs\", \"sandy_cheeks\", \"sheldon_j_plankton\", \"spongebob_squarepants\", \"squidward_tentacles\"]\n",
        "\n",
        "### Model and transforms preparation ###\n",
        "# Create EffNetB2 model\n",
        "effnetb2, effnetb2_transforms = create_effnetb2_model(\n",
        "    num_classes=10\n",
        ")\n",
        "\n",
        "# Load saved weights\n",
        "effnetb2.load_state_dict(\n",
        "    torch.load(\n",
        "        f=\"model_efficientnet_b2.pth\",\n",
        "        map_location=torch.device(\"cpu\")\n",
        "    )\n",
        ")\n",
        "\n",
        "### Predict function ###\n",
        "\n",
        "# Create predict function\n",
        "def predict(img) -> Tuple[Dict, float]:\n",
        "  \"\"\"Transforms and performs a prediction on img and returns prediction and time taken.\n",
        "  \"\"\"\n",
        "  # Start the timer\n",
        "  start_time = timer()\n",
        "\n",
        "  # Transform the target image and add a batch dimension\n",
        "  img = effnetb2_transforms(img).unsqueeze(dim=0)\n",
        "\n",
        "  # Put model into evaluation mode and turn on inference mode\n",
        "  effnetb2.eval()\n",
        "  with torch.inference_mode():\n",
        "    # Pass the transformed image through the model and turn the prediction logits into prediction probabilities\n",
        "    pred_probs = torch.softmax(effnetb2(img), dim=1)\n",
        "\n",
        "  # Create a prediction label and prediction probability dictionary for each prediction class (required format for Gradio's output parameter)\n",
        "  pred_labels_and_probs = {class_names[i]:float(pred_probs[0][i]) for i in range(len(class_names))}\n",
        "\n",
        "  # Calculate the prediction time\n",
        "  pred_time = round(timer() - start_time)\n",
        "\n",
        "  # Return the prediction dictionary and prediction time\n",
        "  return pred_labels_and_probs, pred_time\n",
        "\n",
        "### Gradio app ###\n",
        "title = \"Spongebob Chracter Identifier ğŸ§½ğŸ‘–ğŸ™ğŸ¦€ğŸ¿ï¸ğŸğŸ”ğŸ³ğŸ–¥ï¸\"\n",
        "description = \"An EfficientNetB2 feature extractor computer vision model to classify between 10 character from Spongebob Squarepants: Spongebob, Patrick, Squidward, Gary, Mr. Krabs, Mrs.Puff, Sandy, Plankton, Karen, and Pearl\"\n",
        "article = \"Read more at: [Spongebob Character Identifier](https://gulnuravci.github.io/scripts/project_pages/spongebob_identifier.html)\"\n",
        "\n",
        "# Create examples list from \"examples/\" directory\n",
        "example_list = [[\"examples/\" + example] for example in os.listdir(\"examples\")]\n",
        "\n",
        "demo = gr.Interface(fn=predict, # mapping function from input to output\n",
        "                    inputs=gr.Image(type=\"pil\"), # what are the inputs?\n",
        "                    outputs=[gr.Label(num_top_classes=10, label=\"Predictions\"), # what are the outputs?\n",
        "                             gr.Number(label=\"Prediction time (s)\")], # our fn has two outputs, therefore we have two outputs\n",
        "                    examples=example_list,\n",
        "                    title=title,\n",
        "                    description=description,\n",
        "                    article=article)\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "uO__fw_om-UQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d581ef76-1c31-4785-d3c3-4e89f3143f93"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing demos/spongebob_character_identifier/app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile demos/spongebob_character_identifier/requirements.txt\n",
        "torch>=1.12.0\n",
        "torchvision>=0.13.0\n",
        "gradio>=3.1.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKfqd6xStrcj",
        "outputId": "6d51304c-1abc-40e1-96b2-60797a79654f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing demos/spongebob_character_identifier/requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls demos/spongebob_character_identifier"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEAk0lp1r2Ik",
        "outputId": "7a029186-6dfd-4558-feac-a1e9749ea60c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "app.py\texamples  model_efficientnet_b2.pth  model.py  requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change into and then zip the spongebob_character_identifier folder but exclude certain files\n",
        "!cd demos/spongebob_character_identifier && zip -r ../spongebob_character_identifier.zip * -x \"*.pyc\" \"*.ipynb\" \"*__pycache__*\" \"*ipynb_checkpoints*\"\n",
        "\n",
        "# Download the zipped app\n",
        "try:\n",
        "  from google.colab import files\n",
        "  files.download(\"demos/spongebob_character_identifier.zip\")\n",
        "except:\n",
        "  print(\"Not running in Google Colab, can't use google.colab.files.download(), please manually download.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "V5utqZklraGC",
        "outputId": "932feae7-6db3-46d8-d85a-615baacac59d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: app.py (deflated 54%)\n",
            "  adding: examples/ (stored 0%)\n",
            "  adding: examples/gary_the_snail_54.jpg (deflated 1%)\n",
            "  adding: examples/pearl_krabs_45.jpg (deflated 3%)\n",
            "  adding: examples/squidward_tentacles_101.jpg (deflated 2%)\n",
            "  adding: model_efficientnet_b2.pth (deflated 8%)\n",
            "  adding: model.py (deflated 55%)\n",
            "  adding: requirements.txt (deflated 4%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5e8a8f10-9603-424b-b6f7-834f0d31c0bd\", \"spongebob_character_identifier.zip\", 29046061)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import IFrame\n",
        "\n",
        "IFrame(src=\"https://huggingface.co/spaces/gulnuravci/spongebob_character_identifier\", width=900, height=750)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "id": "WJzl4Efnupqh",
        "outputId": "71ce2cbc-64c2-4238-a09b-4fc093049e12"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7c8a9fc230d0>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"900\"\n",
              "            height=\"750\"\n",
              "            src=\"https://huggingface.co/spaces/gulnuravci/spongebob_character_identifier\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    }
  ]
}